{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities, utils\n",
    "import numpy as np\n",
    "import nltk\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "在`gensim`中，最基本的representation是document-term的組合，例如`corpus[0]`代表第一個document內所包含的term及出現次數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " corpus = [[(0, 1.0), (1, 1.0), (2, 1.0)],\n",
    "           [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],\n",
    "           [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],\n",
    "           [(0, 1.0), (4, 2.0), (7, 1.0)],\n",
    "           [(3, 1.0), (5, 1.0), (6, 1.0)],\n",
    "           [(9, 1.0)],\n",
    "           [(9, 1.0), (10, 1.0)],\n",
    "           [(9, 1.0), (10, 1.0), (11, 1.0)],\n",
    "           [(8, 1.0), (10, 1.0), (11, 1.0)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformation則是用來將一種representation轉換成另一種。\n",
    "\n",
    "以下面的例子來說，我們先由corpus產生一個tfidf model，這個model的用途是將未來看到的document-term vector轉換成tfidf。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.5547001962252291), (2, 0.8320502943378437)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "tfidf[(0, 2.0), (2, 3.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要取得原本corpus的vector，需要用tfidf model轉換一次。\n",
    "\n",
    "下面將轉換的結果產生一個similarity matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sims = index[tfidf[(0, 2.0), (2, 3.0)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80064076,  0.36963463,  0.        ,  0.27281573,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個結果表示(0,2)-(2,3)的document，與文件[0]具有80%的相似度，和文件[1]具有36%、文件[3]具有27%的相似度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpora and Vector Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "cnt = nltk.FreqDist(list(itertools.chain.from_iterable(texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntexts = [[term for term in doc if cnt[term] > 1] for doc in texts]\n",
    "ntexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict = corpora.Dictionary(ntexts)\n",
    "# dict.save('corpus.dict')  # 存到檔案中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'computer': 1,\n",
       " u'eps': 8,\n",
       " u'graph': 10,\n",
       " u'human': 2,\n",
       " u'interface': 0,\n",
       " u'minors': 11,\n",
       " u'response': 3,\n",
       " u'survey': 5,\n",
       " u'system': 6,\n",
       " u'time': 4,\n",
       " u'trees': 9,\n",
       " u'user': 7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.doc2bow(\"Human computer interaction\".lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(0, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(2, 1), (6, 2), (8, 1)],\n",
       " [(3, 1), (4, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(5, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dict.doc2bow(text) for text in texts]\n",
    "# corpora.MmCorpus.serialize('corpus.mm', corpus)  # 存到檔案中\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Streaming\n",
    "\n",
    "在上面的作法中，整個corpus都放在記憶體裡。如果corpus太大，一種可行的作法是一次讀一部分，這時可以自定義corpus class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in open('mycorpus.txt'):\n",
    "            # 假設每一行代表一個document，而且tokens以空白字元分隔\n",
    "            yield dict.doc2bow(line.lower().split())\n",
    "            # 這裡用yield會變成一個generator，因此可以將物件放在for裡面\n",
    "            # 例如 for line in myCorpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyCorpus at 0x7f5e4ce67890>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCorpus = MyCorpus()\n",
    "myCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(0, 1), (6, 1), (7, 1), (8, 1)]\n",
      "[(2, 1), (6, 2), (8, 1)]\n",
      "[(3, 1), (4, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(5, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "for vec in myCorpus:\n",
    "    print vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同樣的，建立dictionary時，也可以用這樣的技巧避免載入檔案到記憶體。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(42 unique tokens: [u'and', u'minors', u'generation', u'testing', u'iv']...)\n"
     ]
    }
   ],
   "source": [
    "dict2 = corpora.Dictionary(line.lower().split() for line in open(\"mycorpus.txt\"))\n",
    "print dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n"
     ]
    }
   ],
   "source": [
    "stopid = [dict2.token2id[s] for s in stoplist]\n",
    "onceid = [id for id, freq in dict2.dfs.iteritems() if freq == 1]\n",
    "dict2.filter_tokens(stopid + onceid)\n",
    "dict2.compactify()\n",
    "print dict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Formats\n",
    "\n",
    "* Market Matrix format\n",
    "    * 儲存: `corpora.MmCorpus.serialize('corpus.mm', myCorpus)`\n",
    "    * 載入: `myCorpus = corpora.MmCorpus('corpus.mm')`\n",
    "* Joachim's SVMlight format\n",
    "    * 儲存: `corpora.SvmLightCorpus.serialize('corpus.svml', myCorpus)`\n",
    "    * 載入: `myCorpus = corpora.SvmLightCorpus('corpus.svml')`\n",
    "* Blei's LDA-C format\n",
    "    * 儲存: `corpora.BleiCorpus.serialize('corpus.ldac', myCorpus)`\n",
    "    * 載入: `myCorpus = corpora.BleiCorpus('corpus.ldac')`\n",
    "* GibbsLDA++ format\n",
    "    * 儲存: `corpora.LowCorpus.serialize('corpus.low', myCorpus)`\n",
    "    * 載入: `myCorpus = corpora.LowCorpus('corpus.low')`\n",
    "\n",
    "corpus在使用時，也可以用streaming的方式:\n",
    "```\n",
    "for doc in corpus:\n",
    "    print doc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compatibility with NumPy and SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "# term-document matrix\n",
    "numpy_matrix = np.array([[1,2,3,4],[2,4,5,6]])\n",
    "corpus = gensim.matutils.Dense2Corpus(numpy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.],\n",
       "       [ 2.,  4.,  5.,  6.],\n",
       "       [ 0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_matrix = gensim.matutils.corpus2dense(corpus, num_terms=3)\n",
    "numpy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x3 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = gensim.matutils.Sparse2Corpus(sparse.rand(5, 3))\n",
    "scipy_matrix = gensim.matutils.corpus2csc(corpus, 5)\n",
    "scipy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
