{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch3 Processing Raw Text\n",
    "\n",
    "本章要回答幾個問題\n",
    "\n",
    "1. 如何從本地端的檔案或網路上取得文字\n",
    "2. 如何將文件拆成單字和符號\n",
    "3. 如何產生格式化的輸出並儲存到檔案中\n",
    "\n",
    "**注意**: 從這章開始，都會假設程式已經導入下列library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Text from the Web and from Disk\n",
    "\n",
    "### Electronic Books\n",
    "\n",
    "Gutenberg上每一本電子書都有編號，只要知道編號就可以下載電子書，例如\"Crime and Punishment\"是第2554號，可以用下面的方法取得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import urlopen\n",
    "url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
    "raw = urlopen(url).read()\n",
    "type(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "註：如果要使用proxy下載，可以用\n",
    "```\n",
    "proxy = {'http': 'http://www.someproxy.com:3128'}\n",
    "raw = urlopen(url, proxies=proxy).read()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "剛下載的`raw`是字串形態，包含許多不必要的字，所以需要**tokenization**，使單字分離。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "產生的token可以進一步轉換成nltk text形態，以便進一步處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: The Project Gutenberg EBook of Crime and Punishment...>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; Nikodim Fomitch; young man; Ilya Petrovitch; n't know;\n",
      "Project Gutenberg; Dmitri Prokofitch; Andrey Semyonovitch; Hay Market\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = urlopen(url).read()\n",
    "html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'BBC', u'NEWS', u'|', u'Health', u'|']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(bs.get_text())\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`concordance`列出單字出現的每個地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 7 of 7 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n",
      "er's Polio campaign launched in Iraq Gene defect explains high blood pressure \n",
      "er's Polio campaign launched in Iraq Gene defect explains high blood pressure \n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings: Lowest Level Text\n",
    "\n",
    "字串是一種**immutable**的資料形態，設定值之後就不能修改。因此所有字串函式都會產生複製後的字串，而不會修改原始的字串。\n",
    "\n",
    "用三個引號`\"\"\"`來定義字串，可以將換行一起放進去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, my\n",
      "friend\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"hello, my\n",
    "friend\"\"\"\n",
    "print s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`str`支援`+`和`*`兩個operator。`+`代表連接兩個字串，`*`代表重複一個字串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mustmaybehello'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'must' + 'maybe' + 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bug-bug-bug-bug-bug-'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'bug-' * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用`[i]`可以存取第i+1個字元，如果字串長度是n，則i的範圍為0到n-1。  \n",
    "用`[-i]`可以存取後面數過來第i個字元，如果字串長度是n，則i的範圍為-1到-n。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('h', 'e', 'hello', 'world')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'hello, world'\n",
    "s[0], s[1], s[:5], s[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他常見的字串函式:\n",
    "\n",
    "* `s.find(t)`: 找到字串s內第一個字串t的位置，介於0~n-1間，找不到傳回-1\n",
    "* `s.rfind(t)`: 從右邊找字串s內第一個字串t的位置，介於0~n-1間，找不到傳回-1\n",
    "* `s.index(t)`: 功能如`s.find(t)`，但找不到時會產生ValueError\n",
    "* `s.rindex(t)`: 功能如`s.rfind(t)`，但找不到時會產生ValueError\n",
    "* `s.join([a,b,c])`: 將字串a,b,c結合，中間插入s，最後結果為asbsc\n",
    "* `s.split(t)`: 用字串t為分隔，將s拆成多個字串，預設t為空白字元\n",
    "* `s.splitlines()`: 將字串s根據換行拆成多個字串\n",
    "* `s.lower()`: 將所有字母換成小寫\n",
    "* `s.upper()`: 將所有字母換成大寫\n",
    "* `s.titlecase()`: 每個單字第一個字母換成大寫\n",
    "* `s.strip()`: 刪除前後的空白字元\n",
    "* `s.replace(t, u)`: 將s中的字串t替換成字串u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing with Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = nltk.data.find('corpora/unicode_samples/polish-lat2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruska Biblioteka Państwowa. Jej dawne zbiory znane pod nazwą\n",
      "Pruska Biblioteka Państwowa. Jej dawne zbiory znane pod nazwą\n",
      "Pruska Biblioteka Pa\\u0144stwowa. Jej dawne zbiory znane pod nazw\\u0105\\n \n",
      "\n",
      "\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\n",
      "\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\n",
      "\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\\n \n",
      "\n",
      "Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały\n",
      "Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały\n",
      "Niemc\\xf3w pod koniec II wojny \\u015bwiatowej na Dolny \\u015al\\u0105sk, zosta\\u0142y\\n \n",
      "\n",
      "odnalezione po 1945 r. na terytorium Polski. Trafiły do Biblioteki\n",
      "odnalezione po 1945 r. na terytorium Polski. Trafiły do Biblioteki\n",
      "odnalezione po 1945 r. na terytorium Polski. Trafi\\u0142y do Biblioteki\\n \n",
      "\n",
      "Jagiellońskiej w Krakowie, obejmują ponad 500 tys. zabytkowych\n",
      "Jagiellońskiej w Krakowie, obejmują ponad 500 tys. zabytkowych\n",
      "Jagiello\\u0144skiej w Krakowie, obejmuj\\u0105 ponad 500 tys. zabytkowych\\n \n",
      "\n",
      "archiwaliów, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\n",
      "archiwaliów, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\n",
      "archiwali\\xf3w, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\\n \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "f = codecs.open(path, encoding='latin2')\n",
    "for line in f:\n",
    "    print line, line.encode('utf-8'), line.encode('unicode_escape'), '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35377 27946 33995\n"
     ]
    }
   ],
   "source": [
    "# 傳回unicode的編號\n",
    "print ord(u'許'), ord(u'洪'), ord(u'蓋')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'\\u8a31\\u6d2a\\u84cb'\n"
     ]
    }
   ],
   "source": [
    "print repr(u'許洪蓋')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unicodedata`可以印出unicode中對字元的描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niemc\\xf3w pod koniec II wojny \\u015bwiatowej na Dolny \\u015al\\u0105sk, zosta\\u0142y\\n\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "lines = codecs.open(path, encoding='latin2').readlines()\n",
    "line = lines[2]\n",
    "print line.encode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ó U+00f3 LATIN SMALL LETTER O WITH ACUTE\n",
      "ś U+015b LATIN SMALL LETTER S WITH ACUTE\n",
      "Ś U+015a LATIN CAPITAL LETTER S WITH ACUTE\n",
      "ą U+0105 LATIN SMALL LETTER A WITH OGONEK\n",
      "ł U+0142 LATIN SMALL LETTER L WITH STROKE\n"
     ]
    }
   ],
   "source": [
    "for c in line:\n",
    "    if ord(c) > 127:\n",
    "        print '%s U+%04x %s' % (c.encode('utf8'), ord(c), unicodedata.name(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "* `.`: 對應任意一個字元\n",
    "* `^abc`: 字串開頭為abc\n",
    "* `abc$`: 字串結尾為abc\n",
    "* `[abc]`: 對應`[]`內出現的字元，例如a或b或c\n",
    "* `[A-Z0-9]`: 對應範圍內的字元，例如A到Z以及0到9\n",
    "* `ed|ing|s`: 對應數種指定的字串\n",
    "* `*`: 前一個符號重複0次以上\n",
    "* `+`: 前一個符號重複1次以上\n",
    "* `?`: 前一個符號重複0次或1次\n",
    "* `{n}`: 前一個符號重複恰好n次\n",
    "* `{n,}`: 前一個符號重複至少n次\n",
    "* `{,n}`: 前一個符號重複最多n次\n",
    "* `{m,n}`: 前一個符號重複最少m次、最多n次\n",
    "* `a(b|c)+`: 括號表示`|`運算的範圍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一般re.search傳回的是一個 _sre.SRE_Match 物件\n",
    "# 將物件轉換成 bool 值，如果 True 代表有找到符合的字串\n",
    "bool(re.search('ed$', 'played')), bool(re.search('ed$', 'happy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bany', 'Dog']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.findall 可以取出部分的字串，要取出的部分由()的範圍決定\n",
    "re.findall('\\[\\[(.+?)[\\]|\\|]+', 'My Name is [[Bany]] Hung, this is my [[Dog|Animal]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My Name is ### Hung, this is my ###Animal]]'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.sub 會取代字串\n",
    "re.sub('\\[\\[.+?[\\]|\\|]+', '###', 'My Name is [[Bany]] Hung, this is my [[Dog|Animal]]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Text\n",
    "\n",
    "正規化是指將文字變成統一的格式，例如轉成小寫、取字根。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', u'I', 'i'),\n",
       " ('was', u'wa', 'was'),\n",
       " ('playing', u'play', 'play'),\n",
       " ('television', u'televis', u'televid'),\n",
       " ('in', u'in', 'in'),\n",
       " ('the', u'the', 'the'),\n",
       " ('painted', u'paint', 'paint'),\n",
       " ('garden', u'garden', 'gard')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lanc = nltk.LancasterStemmer()\n",
    "w = ['I','was','playing','television','in','the','painted','garden']\n",
    "[(a, porter.stem(a), lanc.stem(a)) for a in w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作stemming之前，要將原始資料存在dict中，以方便使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IndexedText(object):\n",
    "    def __init__(self, stemmer, text):\n",
    "        self._text = text\n",
    "        self._stemmer = stemmer\n",
    "        self._index = nltk.Index((self._stem(word), i) for (i, word) in enumerate(text))\n",
    "        \n",
    "    def concordance(self, word, width=40):\n",
    "        key = self._stem(word)\n",
    "        wc = int(width/4)                # words of context\n",
    "        for i in self._index[key]:\n",
    "            lcontext = ' '.join(self._text[i-wc:i])\n",
    "            rcontext = ' '.join(self._text[i:i+wc])\n",
    "            ldisplay = '%*s'  % (width, lcontext[-width:])\n",
    "            rdisplay = '%-*s' % (width, rcontext[:width])\n",
    "            print ldisplay, rdisplay\n",
    "            \n",
    "    def _stem(self, word):\n",
    "        return self._stemmer.stem(word).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r king ! DENNIS : Listen , strange women lying in ponds distributing swords is no\n",
      " beat a very brave retreat . ROBIN : All lies ! MINSTREL : [ singing ] Bravest of\n",
      "       Nay . Nay . Come . Come . You may lie here . Oh , but you are wounded !   \n",
      "doctors immediately ! No , no , please ! Lie down . [ clap clap ] PIGLET : Well  \n",
      "ere is much danger , for beyond the cave lies the Gorge of Eternal Peril , which \n",
      "   you . Oh ... TIM : To the north there lies a cave -- the cave of Caerbannog --\n",
      "h it and lived ! Bones of full fifty men lie strewn about its lair . So , brave k\n",
      "not stop our fight ' til each one of you lies dead , and the Holy Grail returns t\n"
     ]
    }
   ],
   "source": [
    "grail = nltk.corpus.webtext.words('grail.txt')\n",
    "text = IndexedText(porter, grail)\n",
    "text.concordance('lie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('women', 'women', u'woman'),\n",
       " ('are', u'be', 'are'),\n",
       " ('living', u'live', 'living')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ['women', 'are', 'living']\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "zip(s, [wnl.lemmatize(t, 'v') for t in s], [wnl.lemmatize(t, 'n') for t in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting: From Lists to Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We called him Tortoise because he taught us .'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ['We', 'called', 'him', 'Tortoise', 'because', 'he', 'taught', 'us', '.']\n",
    "' '.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We;called;him;Tortoise;because;he;taught;us;.'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "';'.join(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
