{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pymongo.MongoClient`\n",
    "\n",
    "### Overview\n",
    "\n",
    "* 產生一個client物件，用來連接MongoDB、replica set、或set of mongoses。\n",
    "* client物件設計為thread-safe並支援connection-pooling。\n",
    "* 如果網路連線中斷導致操作失敗，會產生`ConnectionFailure`並在背景重新連線，應用程式要用`try...except`處理此例外情況，然後繼續執行。\n",
    "* 舊版的`alive()`拿掉了，因為無論是否已連線，當操作時都會在背景自動連線。\n",
    "* 連線到mongoses時，會在背景監控每台mongoses的網路延遲，並自動將操作分散到延遲較低的機器上。\n",
    "\n",
    "### Init Parameters\n",
    "\n",
    "1. `host`: 可以是單純的ip address，也可以是完整的mongodb URI，例如`'mongodb://user:pass@10.0.0.1:27017'`。在URI中設定的port會覆蓋`port`參數的設定。ip address可以是ipv6，例如`'[::1]'`等同於`'localhost'`。如果要連線到replica set或mongoses，`host`參數可以是list of strings，連線時會一個一個嘗試，並使用最後一個連線正確的host。預設值為`'localhost'`。\n",
    "2. `port`: 連線的port number，預設為`27017`。\n",
    "3. `document_class`: 執行query時，傳回文件的資料型態，預設為`dict`。\n",
    "4. `tz_aware`: 設為`True`，文件中的時間會作時區調整，預設為`False`。\n",
    "5. `connect`: 設為`True`，會馬上在背景連線到MongoDB；預設為`False，會在第一次操作時才連線。\n",
    "6. 連線參數\n",
    "    * `maxPoolSize`: 這個client的connection pool大小，代表同時連線的數量，預設為`100`，不可以設為`0`。\n",
    "    * `socketTimeoutMS`: 送出操作後等多少milliseconds算是timeout，預設為`None`代表沒有timeout。\n",
    "    * `connectTimeoutMS`: 第一次連線等多少milliseconds會判定為server離線，預設為`20000`代表20秒，設為`None`代表沒有timeout。\n",
    "    * `serverSelectionTimeoutMS`: 當`host`是list時，總共可以花多少milliseconds來找正確的server。對應每個server會產生一個連線，每個連線的時間受限於`connectTimeoutMS`。預設值為`30000`代表30秒。\n",
    "    * `waitQueueTimeoutMS`: 當connection pool已滿時，新的連線等多少milliseconds算是timeout，預設為`None`代表沒有timeout。\n",
    "    * `waitQueueMultiple`: 當connection pool已滿時，可以有多少個等待連線。`waitQueueMultiple`乘上`maxPoolSize`就是最大等待數量。預設值為`None`代表沒有限制。\n",
    "    * `socketKeepAlive`: 已連線的socket是否要定期送keep-alive來保持連線。預設為`False`。\n",
    "    * `event_listeners`: 包含event listener的list或tuple。\n",
    "7. 寫入保險參數\n",
    "    * `w`: 當連線到replica set時，寫入操作應該要複製幾次。例如`w=3`代表寫入primary後，會被block直到文件複製兩次。設`w=0`表示不考慮。\n",
    "    * `wtimeout`: 必須和`w`一起使用，表示write propagation要等多少milliseconds算是timeout。\n",
    "    * `j`: 設為`True`，寫入時要等真的寫入journal才會返回。在MongoDB 2.6之前的版本此參數無效果。在MongoDB 2.6之後，如果MongoDB沒有開journaling功能，則每次寫入都會產生exception。此參數不能與`fsync`同時使用。\n",
    "    * `fsync`: 設為`True`，如果MongoDB沒有journaling，會等資料真的寫入硬碟才會返回。如果MongoDB有journaling，則效果與`j`相同，會等寫入journal才返回。此參數不能與`j`同時使用。\n",
    "8. Replica Set參數\n",
    "    * `replicaSet`: 設定要連線的replica set的名稱，連線時會從`host` list中找所有符合此名稱的member，預設為`None`。\n",
    "    * `read_preference`: 所有可用的read preference參數請參考`ReadPreference`。預設值為`PRIMARY`。\n",
    "9. SSL參數\n",
    "    * `ssl`: 設為`True`代表使用SSL連線，預設為`False`。\n",
    "    * `ssl_keyfile`: 代表private key的檔案位置，設定此值會使`ssl=True`。預設值為`None`。\n",
    "    * `ssl_certfile`: 代表certificate的檔案位置，設定此值會使`ssl=True`。預設值為`None`。\n",
    "    * `ssl_cert_reqs`: 反向連線時是否需要驗證，此參數可用的值為`ssl.CERT_NONE`(不需驗證)、`ssl.CERT_OPTIONAL`(不需驗證，但有提供驗證機制)、`ssl.CERT_REQUIRED`(強制驗證)。如果設為`ssl.CERT_OPTIONAL`或`ssl.CERT_REQUIRED`，則CA certificate會優先從`ssl_ca_certs`參數取得，如果沒有則向作業系統索取。設定此值會使`ssl=True`。當`ssl=True`時，預設值為`ssl.CERT_REQUIRED`。\n",
    "    * `ssl_ca_certs`: 代表CA cerficicate的檔案位置，用來驗證反向連線，設定此值會使`ssl=True`。預設值為`None`。\n",
    "    * `ssl_match_hostname`: 預設值為`True`，表示用Python的`ssl.match_hostname()`驗證hostname。要設為`False`前要小心，可能會讓你的應用程式受到man-in-the-middle攻擊。\n",
    "10. 讀取保險參數\n",
    "    * `readConcernLevel`: 設定讀取操作的isolation level。例如設為`majority`只會傳回寫入超過半數node的資料，一般都不設定使用server預設值。\n",
    "\n",
    "### Methods and Members\n",
    "\n",
    "1. `close()`: 結束所有connection pool的連線，並停止monitor thread。但如果對closed client作操作，又會在背景自動連線並啟動monitor thread。\n",
    "2. `client[db_name]` 或 `client.db_name`: 傳回`db_name`對應的`Database`物件。如果該名稱不存在，會傳回`InvalidName`。\n",
    "3. `address`: 一個tuple `(host, port)`代表目前的連線。如果這個client是連線到mongoses，讀取此值會產生`InvalidOperation`，應該用`nodes`取代。如果client未連線，則讀取此值會自動連線，過程中可能產生`ServerSelectionTimeoutError`。\n",
    "4. `is_primary`: `True`表示已經連線而且可以寫入。如果client未連線，則讀取此值會自動連線，過程中可能產生`ServerSelectionTimeoutError`。\n",
    "5. `is_mongos`: `True`表示連線到mongos。如果client未連線，則讀取此值會自動連線，過程中可能產生`ServerSelectionTimeoutError`。\n",
    "6. `max_pool_size`: 同時連線的socket的最大數量。如果pool達到此數量，所有操作都會block，直到其他socket釋放出空位為止。如果有設`waitQueueTimeoutMS`，則block的時間有上限。\n",
    "7. `nodes`: 目前連線的server清單，資料型態是`frozenset`。當連線到replica set時，這個清單會隨時改變，在剛開始還沒連線時也可能為空。\n",
    "8. `max_bson_size`: server最大的BSON物件是多少bytes。如果client未連線，則讀取此值會自動連線，過程中可能產生`ServerSelectionTimeoutError`。\n",
    "9. `max_message_size`: server最長的message是多少bytes。如果client未連線，則讀取此值會自動連線，過程中可能產生`ServerSelectionTimeoutError`。\n",
    "10. `read_preference`: 唯讀的read preference。\n",
    "11. `write_concern`: 唯讀的write concern。\n",
    "12. `is_locked`: server是否為鎖定狀態。鎖定時所有write都會被block，但read仍然可以用。要透過`unlock()`來解鎖。\n",
    "13. `database_names()`: 傳回所有database的名稱。\n",
    "14. `drop_database(name_or_database)`: 刪除一個database，參數是database的名稱或是`Database`物件，資料型態錯誤會產生`TypeError`。\n",
    "15. `get_default_database()`: 如果URI中有設定default database，可透過此方法讀取，否則會產生`ConfigurationError`。\n",
    "16. `get_database(name, codec_options=None, read_preference=None, write_concern=None, read_concern=None)`: 根據給定的名稱和選項取得`Database`物件。通常用在你希望的選擇與client預設值不同時。\n",
    "    * `codec_options`: `None`或是`CodecOptions`物件\n",
    "    * `read_preference`: `None`或是`pymongo.read_preferences`所屬的物件\n",
    "    * `write_concern`: `None`或是`WriteConcern`物件\n",
    "    * `read_concern`: `None`或是`ReadConcern`物件\n",
    "17. `server_info()`: 傳回server資訊。\n",
    "18. `close_cursor(cursor_id, address=None)`: 關閉指定cursor的連線，如果`cursor_id`不是`int`或`long`會產生`TypeError`。`address`可設為`(host, port)`。\n",
    "19. `kill_cursors(cursor_id, address=None)`: 送出kill message給指定的cursor，如果`cursor_id`不是`int`或`long`會產生`TypeError`。`address`可設為`(host, port)`。\n",
    "20. `set_cursor_manager(manager_class)`: 設定client cursor manager，`manager_class`必須是`CursorManager`的subclass。cursor manager用來決定什麼時候要真正殺掉一個closed cursor。\n",
    "21. `fsync(**kwargs)`: 送出所有延遲的寫入，參數設`lock=True`會在送出後鎖定server來禁止寫入，參數設`async=True`則會馬上返回。`lock`及`async`不可以同時使用。在Windows，MongoDB不支援`async`模式。\n",
    "22. `unlock()`: 解除server的鎖定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pymongo.database.Database`\n",
    "\n",
    "### Overview\n",
    "\n",
    "* Database level的工具\n",
    "\n",
    "\n",
    "### Init Parameters\n",
    "\n",
    "1. `client`: 一個`MongoClient`物件。\n",
    "2. `name`: database的名稱，如果不是字串會產生`TypeError`，如果不存在會產生`InvalidName`。\n",
    "3. `codec_options`: `CodecOptions`物件或是`None`使用client的設定。\n",
    "4. `read_preference`: 設定read preference或是`None`使用`client.read_preference`的設定。\n",
    "5. `write_concern`: `WriteConcern`物件或是`None`使用client的設定。\n",
    "6. `read_concern`: `ReadConcern`物件或是`None`使用client的設定。\n",
    "\n",
    "\n",
    "### Methods and Members\n",
    "\n",
    "1. `db[collection_name]` 或 `db.collection_name`: 取得名稱為`collection_name`的`Collection`物件，如果名稱不存在會產生`InvalidName`。\n",
    "2. `codec_options`: 唯讀的`CodecOptions`物件\n",
    "3. `read_preference`: 唯讀的read preference\n",
    "4. `write_concern`: 唯讀的`WriteConcern`物件\n",
    "5. `add_user(name, password=None, read_only=None, **kwargs)`\n",
    "    * 為這個database新增使者\n",
    "    * `name`: 使用者名稱。\n",
    "    * `password`: 使用者密碼，如果使用者已存在，則會修改密碼。\n",
    "    * `read_only`: 設為`True`表示使用者只有讀的權限。\n",
    "6. `authenticate(name, password, source, mechanism, **kwargs)`\n",
    "    * 登入使用者以取得database使用權限，權限會持續到client物件消失或是呼叫`logout()`\n",
    "    * 多次登入但用不同的credential是不合法的，應該先`logout()`登出再重新登入。\n",
    "    * 多個thread共用一個client時，只需登入一次。如果希望多個thread用不同的帳號密碼，應該獨立client。\n",
    "    * 驗證失敗會產生`PyMongoError`的subclass。\n",
    "    * `name`: 使用者名稱。如果不是字串會產生`TypeError`。\n",
    "    * `password`: 使用者密碼。如果不是字串會產生`TypeError`。\n",
    "    * `source`: 要登入的database名稱，不指定代表目前的database。如果不是字串會產生`TypeError`。\n",
    "    * `mechanism`: 驗證機制，預設為`'DEFAULT'`，代表`SCRAM-SHA-1`。\n",
    "7. `client`: 這個`Database`對應的`MongoClient`物件。\n",
    "8. `collection_names(include_system_collections)`\n",
    "    * 取得collection名稱列表。\n",
    "    * `include_system_collections`: 預設`True`會包含系統的collection，例如`system.indexes`。\n",
    "9. `command(command, value, check, allowable_errors, read_preference, codec_option, **kwargs)`\n",
    "    * `command`: 如果`command`是字串，會送出`{command: value}`到server上。如果`command`是`dict`，就直接送出。如果`command`是字串，也可以用`kwargs`補充，例如`command('aaa','bbb',cc='dd')`會送出`{aaa:'bbb', cc:'dd'}`。\n",
    "    * `value`: 作為第一個`command`的參數。\n",
    "    * `check`: 是否檢查回應，預設為`True`，當回應有錯誤時，會產生`OperationFailure`。\n",
    "    * `allowable_errors`: 如果`check=True`，則忽略這些錯誤。預設為`None`。\n",
    "    * `read_preference`: 這個操作的read preference，預設為`Primary()`。\n",
    "    * `codec_options`: 一個`CodecOptions`物件，預設為`CodecOptions(document_class=dict, tz_aware=False, uuid_representation=PYTHON_LEGACY, unicode_decode_error_handler='strict', tzinfo=None)`。\n",
    "10. `create_collection(name, codec_options, read_preference, write_concern, read_concern, **kwargs)`\n",
    "    * 在此database建立一個新的collection。一般情況下，建立collection是自動的，但如果你希望建立時有其他參數，就可以用此方法。如果collection已經存在，會產生`CollectionInvalid`。\n",
    "    * `name`: 新建的collection名稱。\n",
    "    * `codec_options`: 指定`CodecOptions`物件，預設為`None`。\n",
    "    * `read_preference`: 指定read preference，預設為`None`。\n",
    "    * `write_concern`: 指定`WriteConcern`物件，預設為`None`。\n",
    "    * `read_concern`: 指定`ReadConcern`物件，預設為`None`。\n",
    "    * `size`: 初始化時的容量(bytes)。如果`capped=True`，則這個值代表collection的最大容量。\n",
    "    * `capped`: 設為`True`會變成capped collection。\n",
    "    * `max`: 如果`capped=True`，這個值代表最大的物件數量。\n",
    "11. `current_op(include_all=False)`: 傳回目前正執行中的operation，如果`include_all=True`則會包含idle中的operation。\n",
    "12. `dereference(dbref, **kwargs)`: 根據`DBRef`找到對應的文件。如果`dbref`不是一個`DBRef`物件會產生`TypeError`。如果找不到文件，會傳回`None`。如果文件所在的database與目前的不同，會產生`ValueError`。`kwargs`可以給如同`find()`在用的參數。\n",
    "13. `drop_collection(name_or_collection)`: 刪除一個collection，`name_or_collection`是collection名稱或是`Collection`物件。\n",
    "14. `get_collection(name, codec_options=None, read_preference=None, write_concern=None, read_concern=None)`\n",
    "    * 通常在你要取得的collection的codec與database預設值不同時，才需要用到此方法。\n",
    "    * `name`: 要取得的collection名稱。\n",
    "    * `codec_options`: 指定`CodecOptions`物件，預設為`None`。\n",
    "    * `read_preference`: 指定read preference，預設為`None`。\n",
    "    * `write_concern`: 指定`WriteConcern`物件，預設為`None`。\n",
    "    * `read_concern`: 指定`ReadConcern`物件，預設為`None`。\n",
    "15. `incoming_copying_manipulators`: 一群copying manipulator，用來處理輸入的SON。\n",
    "16. `incoming_manipulators`: 一群manipulator，用來處理輸入的SON。\n",
    "17. `logout()`: 登出目前的帳號。\n",
    "18. `name`: `Database`的名稱。\n",
    "19. `outgoing_copying_manipulators`: 一群copying manipulator，用來處理輸出的SON。\n",
    "20. `outgoing_manipulators`: 一群manipulator，用來處理輸出的SON。\n",
    "21. `profiling_info()`: 傳回profiling資訊。\n",
    "22. `profiling_level()`: 傳回profiling level，值為`{OFF, SLOW_ONLY, ALL}`。\n",
    "23. `set_profiling_level(level, slow_ms=None)`: 設定profiling level，`level`可以設為`{OFF, SLOW_ONLY, ALL}`。OFF代表不作profiling，SLOW_ONLY代表只看slow operations，ALL代表對所有operations作profiling。執行時間超過`slow_ms`的operation會視為slow operation。\n",
    "24. `remove_user(name)`: 移除使用者帳號`name`。\n",
    "25. `system_js`: 傳回database的`SystemJS` helper物件。\n",
    "26. `validate_collection(name_or_collection, scandata=False, full=False)`\n",
    "    * 傳回正確性資訊，如果有結構不正確的地方會產生`CollectionInvalid`。\n",
    "    * `name_or_collection`: collection名稱或是`Collection`物件。\n",
    "    * `scandata`: 設為`True`，則除了結構，會作額外的檢查。預設為`False`。\n",
    "    * `full`: 設為`True`，在`scandata=True`時，會詳細檢查document的正確性。預設為`False`。\n",
    "\n",
    "\n",
    "## `pymongo.database.SystemJS(database)`\n",
    "\n",
    "### 用途\n",
    "\n",
    "產生javascript的函式或物件，以協助database操作。`SystemJS`不需要自己產生，一律透過`db.system_js`來取得。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pymongo.collection.Collection`\n",
    "\n",
    "### Overview\n",
    "\n",
    "* Collection level的工具\n",
    "\n",
    "\n",
    "### Init Parameters\n",
    "\n",
    "1. `database`: database的名稱。\n",
    "2. `name`: collection的名稱，如果不是字串會產生`TypeError`，如果不存在會產生`InvalidName`。\n",
    "3. `create`: 設為`True`會馬上建立collection，預設為`False`表示第一次操作時才會建立。\n",
    "4. 其他參數\n",
    "    * `codec_options`: 預設為`None`會延用database的設定，或是設為`CodecOptions`物件\n",
    "    * `read_preference`: 預設為`None`會延用database的設定，或是設為read preference物件\n",
    "    * `write_concern`: 預設為`None`會延用database的設定，或是設為`WriteConcern`物件\n",
    "    * `read_concern`: 預設為`None`會延用database的設定，或是設為`ReadConcern`物件\n",
    "\n",
    "\n",
    "### Methods and Members\n",
    "\n",
    "1. `collection[name]` 或 `collection.name`: 取得名稱為`name`的sub-collection，名稱不正確會產生`InvalidName`。\n",
    "2. `fullname`: 這個collection的完整名稱，通常是`db_name.collection_name`。\n",
    "3. `database`: 指向所在的database的`Database`物件。\n",
    "4. `codec_options`: 唯讀的`CodecOptions`物件。\n",
    "5. `read_preference`: 唯讀的read preference。\n",
    "6. `write_concern`: 唯讀的`WriteConcern`物件。\n",
    "7. `with_options(codec_options=None, read_preference=None, write_concern=None, read_concern=None)`: 以新的參數產生一個複製的`Collection`物件。\n",
    "8. `bulk_write(requests, ordered=True, bypass_document_validation=False)`\n",
    "    * 送出一連串的寫入操作，傳回值是`BulkWriteResult`物件。\n",
    "        * `acknowledged`: 當`WriteConcern(w=0)`時，`acknowledged`會傳回`False`，其他情況會傳回`True`。\n",
    "        * `bulk_api_result`: 傳回值的原始資訊。\n",
    "        * `deleted_count`: 刪除documents的數量。\n",
    "        * `inserted_count`: 插入documents的數量。\n",
    "        * `matched_count`: 符合update條件的documents的數量。\n",
    "        * `modified_count`: 修改documents的數量。\n",
    "        * `upserted_count`: `ReplaceOne`插入的documents的數量。\n",
    "        * `upserted_ids`: `ReplaceOne`插入的documents的id。\n",
    "    * `requests`是list of write operations (`InsertOne`, `UpdateOne`, `UpdateMany`, `ReplaceOne`, `DeleteOne`, `DeleteMany`)\n",
    "    * `ordered`: 預設值`True`代表這些操作會依序執行。如果執行中發生錯誤，後面的操作都會放棄。設為`False`表示可能平行處理，順序是隨機的，所有的操作都會嘗試一次。\n",
    "    * `bypass_document_validation`: 預設值`False`，設為`True`代表允許不合法的document被寫入。\n",
    "9. `insert_one(document, bypass_document_validation=False)`\n",
    "    * 插入一份文件，傳回值為`InsertOneResult`物件。\n",
    "        * `acknowledged`: 當`WriteConcern(w=0)`時，`acknowledged`會傳回`False`，其他情況會傳回`True`。\n",
    "        * `inserted_id`: 插入文件的id。\n",
    "    * `document`: 要插入的文件，必須是mutable mapping，如果沒有`_id`欄位，會自動產生`_id`。\n",
    "    * `bypass_document_validation`: 預設值`False`，設為`True`代表允許不合法的document被寫入。\n",
    "10. `insert_many(documents, ordered=True, bypass_document_validation=False)`\n",
    "    * 插入多份文件，傳回值為`InsertManyResult`物件。\n",
    "        * `acknowledged`: 當`WriteConcern(w=0)`時，`acknowledged`會傳回`False`，其他情況會傳回`True`。\n",
    "        * `inserted_ids`: 插入文件的id。\n",
    "    * `ordered`: 預設值`True`代表這些操作會依序執行。如果執行中發生錯誤，後面的操作都會放棄。設為`False`表示可能平行處理，順序是隨機的，所有的操作都會嘗試一次。\n",
    "    * `bypass_document_validation`: 預設值`False`，設為`True`代表允許不合法的document被寫入。\n",
    "11. `replace_one(filter, replacement, upsert=False, bypass_document_validation=False)`\n",
    "    * 取代一份符合`filter`條件的文件，傳回值為`UpdateResult`物件。\n",
    "        * `acknowledged`: 當`WriteConcern(w=0)`時，`acknowledged`會傳回`False`，其他情況會傳回`True`。\n",
    "        * `raw_result`: 傳回值的原始資料。\n",
    "        * `matched_count`: 符合update條件的documents的數量。\n",
    "        * `modified_count`: 修改documents的數量。\n",
    "        * `upserted_ids`: `replace_one`插入的documents的id。\n",
    "    * `filter`: 要篩選的條件。\n",
    "    * `replacement`: 要取代的文件。\n",
    "    * `upsert`: 設為`True`會在找不到`filter`對應的文件時，插入一份新文件。預設為`False`。\n",
    "    * `bypass_document_validation`: 預設值`False`，設為`True`代表允許不合法的document被寫入。\n",
    "12. `update_one(filter, update, upsert=False, bypass_document_validation=False)`\n",
    "    * 更新一份符合`filter`條件的文件，傳回值為`UpdateResult`物件。\n",
    "        * `acknowledged`: 當`WriteConcern(w=0)`時，`acknowledged`會傳回`False`，其他情況會傳回`True`。\n",
    "        * `raw_result`: 傳回值的原始資料。\n",
    "        * `matched_count`: 符合update條件的documents的數量。\n",
    "        * `modified_count`: 修改documents的數量。\n",
    "        * `upserted_ids`: `replace_one`插入的documents的id。\n",
    "    * `filter`: 要篩選的條件。\n",
    "    * `update`: 要修改的欄位和值。\n",
    "    * `upsert`: 設為`True`會在找不到`filter`對應的文件時，插入一份新文件。預設為`False`。\n",
    "    * `bypass_document_validation`: 預設值`False`，設為`True`代表允許不合法的document被寫入。\n",
    "13. `update_many(filter, update, upsert=False, bypass_document_validation=False)`\n",
    "    * 更新所有符合`filter`條件的文件，傳回值為`UpdateResult`物件。\n",
    "        * `acknowledged`: 當`WriteConcern(w=0)`時，`acknowledged`會傳回`False`，其他情況會傳回`True`。\n",
    "        * `raw_result`: 傳回值的原始資料。\n",
    "        * `matched_count`: 符合update條件的documents的數量。\n",
    "        * `modified_count`: 修改documents的數量。\n",
    "        * `upserted_ids`: `replace_one`插入的documents的id。\n",
    "    * `filter`: 要篩選的條件。\n",
    "    * `update`: 要修改的欄位和值。通常會用特殊語法。\n",
    "    * `upsert`: 設為`True`會在找不到`filter`對應的文件時，插入一份新文件。預設為`False`。\n",
    "    * `bypass_document_validation`: 預設值`False`，設為`True`代表允許不合法的document被寫入。\n",
    "14. `delete_one(filter)`\n",
    "    * 刪除一份符合`filter`條件的文件，傳回值為`DeleteResult`物件。\n",
    "        * `acknowledged`: 當`WriteConcern(w=0)`時，`acknowledged`會傳回`False`，其他情況會傳回`True`。\n",
    "        * `raw_result`: 傳回值的原始資料。\n",
    "        * `deleted_count`: 刪除的documents的數量。\n",
    "    * `filter`: 要篩選的條件。\n",
    "15. `delete_many(filter)`\n",
    "    * 刪除所有符合`filter`條件的文件，傳回值為`DeleteResult`物件。\n",
    "        * `acknowledged`: 當`WriteConcern(w=0)`時，`acknowledged`會傳回`False`，其他情況會傳回`True`。\n",
    "        * `raw_result`: 傳回值的原始資料。\n",
    "        * `deleted_count`: 刪除的documents的數量。\n",
    "    * `filter`: 要篩選的條件。\n",
    "16. `aggregate(pipeline, **kwargs)`\n",
    "    * 使用aggregate架構來運算。所有aggregate參數應該透過`kwargs`來傳入。傳回值是`CommandCursor`物件。\n",
    "    * aggregate使用時會遵守read preference，如果有使用`$$out` pipeline，但read preference卻不是`PRIMARY`，會產生錯誤。\n",
    "    * `pipeline`: a list of aggregation pipeline stages。\n",
    "    * 常見的aggregate參數\n",
    "        * `allowDiskUse`: 是否允許寫入暫存檔，設為`True`，aggregate stage會將暫存檔案寫入`_tmp`目錄，預設為`False`。\n",
    "        * `maxTimeMS`: 允許執行的時間(milliseconds)。\n",
    "        * `batchSize`: 每次batch傳回documents的最大數量。\n",
    "        * `useCursor`: 如果server有支援，要求server透過cursor提供結果。預設為`True`。\n",
    "17. `find(filter=None, projection=None, skip=0, limit=0, no_cursor_timeout=False, cursor_type=CursorType.NON_TAILABLE, sort=None, allow_partial_results=False, oplog_replay=False, modifiers=None, manipulate=True)`\n",
    "    * 查詢database，傳回符合`filter`條件的documents，傳回時只保留`projection`指定的欄位。`find()`會遵守read preference。\n",
    "    * `filter`: 指定篩選條件的SON物件。\n",
    "    * `projection`: 傳回結果要保留的欄位，除非指定`_id:0`，否則`_id`一定會包括在裡面。\n",
    "    * `skip`: 要忽略前幾筆結果。\n",
    "    * `limit`: 一次傳回的最大數量。\n",
    "    * `no_cursor_timeout`: 預設值為`False`，當cursor閒置10分鐘就會被server斷掉。如果設為`True`，cursor永遠不會timeout，所以一定要手動`close()`才能正常關閉。\n",
    "    * `cursor_type`: 選擇cursor類別。\n",
    "        * `NON_TAILABLE`: 標準cursor。\n",
    "        * `TAILABLE`: 用在capped collection上，當最後一筆資料讀取後不會關閉，而會停留在最後一筆document的位置。如果有新的document加入，可以再繼續讀新的資料。\n",
    "        * `TAILABLE_AWAIT`: 當最後一筆資料讀取後，server會等一段時間再關掉cursor，這樣在query過程中插入的document也可以被讀出來。\n",
    "        * `EXHAUST`: MongoDB會主動將資料送給client，而不會等client要求，這可以減少latency。\n",
    "            * `limit`會被忽略。\n",
    "            * sharded cluster不支援這種cursor。\n",
    "    * `sort`: 指定`(key, direction)`來排序傳回的結果。\n",
    "    * `allow_partial_results`: 設為`True`，如果shard nodes當機了，會傳回部分結果而不會產生錯誤。預設為`False`。\n",
    "    * `oplog_replay`: 設為`True`會設定oplogReplay query flag。\n",
    "    * `modifiers`: 型態為`dict`，用來設定query modifier。\n",
    "    * `batch_size`: 一次傳回的documents數量。\n",
    "18. `find_one(filter_or_id=None, *args, **kwargs)`\n",
    "    * 查詢database，傳回一筆符合`filter`條件的document，找不到會傳回`None`。`find_one()`會遵守read preference。\n",
    "    * 所有`find()`的參數都可以用在`find_one()`，除了`limit`。\n",
    "    * `filter`: 指定篩選條件的SON物件。\n",
    "    * `args` 及 `kwargs`: 代表`find()`可用的參數。\n",
    "19. `find_one_and_delete(filter, projection, sort, **kwargs)`\n",
    "    * 查詢database，傳回一筆符合`filter`條件的document，並將document從資料庫刪除，找不到會傳回`None`。會遵守read preference。\n",
    "    * `filter`: 指定篩選條件的SON物件。\n",
    "    * `projection`: 傳回結果要保留的欄位，除非指定`_id:0`，否則`_id`一定會包括在裡面。預設為`None`\n",
    "    * `sort`: 如果有多筆符合的document，要如何選擇。排序後的第一筆將被傳回及刪除。。預設為`None`\n",
    "20. `find_one_and_replace(filter, replacement, projection, sort, return_document, **kwargs)`\n",
    "    * 查詢database，傳回一筆符合`filter`條件的document，並將document從資料庫刪除，插入新的document `replacement`，找不到會傳回`None`。會遵守read preference。\n",
    "    * `filter`: 指定篩選條件的SON物件。\n",
    "    * `replacement`: 要用來取代document。\n",
    "    * `projection`: 傳回結果要保留的欄位，除非指定`_id:0`，否則`_id`一定會包括在裡面。預設為`None`\n",
    "    * `upsert`: 設為`True`會在找不到`filter`對應的文件時，插入一份新文件。預設為`False`。\n",
    "    * `sort`: 如果有多筆符合的document，要如何選擇。排序後的第一筆將被傳回及刪除。。預設為`None`\n",
    "    * `return_document`: 預設值為`ReturnDocument.BEFORE`，代表傳回被刪除的資料，如果找不到符合的會傳回`None`。設為`ReturnDocument.AFTER`則會傳回插入或取代的資料。\n",
    "21. `find_one_and_update(filter, update, projection, sort, return_document, **kwargs)`\n",
    "    * 查詢database，傳回一筆符合`filter`條件的document，並用`update`的資料更新document。會遵守read preference。\n",
    "    * `filter`: 指定篩選條件的SON物件。\n",
    "    * `update`: 要更新的欄位和值。\n",
    "    * `projection`: 傳回結果要保留的欄位，除非指定`_id:0`，否則`_id`一定會包括在裡面。預設為`None`\n",
    "    * `sort`: 如果有多筆符合的document，要如何選擇。排序後的第一筆將被傳回及刪除。。預設為`None`\n",
    "    * `upsert`: 設為`True`會在找不到`filter`對應的文件時，插入一份新文件。預設為`False`。\n",
    "    * `return_document`: 預設值為`ReturnDocument.BEFORE`，代表傳回被刪除的資料，如果找不到符合的會傳回`None`。設為`ReturnDocument.AFTER`則會傳回插入或取代的資料。\n",
    "22. `count(filter=None, **kwargs)`\n",
    "    * 計算符合條件的document數量。\n",
    "    * `filter`: 指定篩選條件的SON物件。\n",
    "    * `hint`: 要使用的index name，可以同時有多個index，如`[('index_a', pymongo.ASCENDING), ('index_b', pymongo.DESCENDING)]`\n",
    "    * `limit`: 要計算的最大數量。\n",
    "    * `skip`: 要忽略前幾筆結果。\n",
    "    * `maxTimeMS`: 這個命令允許執行的最長時間(milliseconds)。\n",
    "23. `distinct(key, filter=None, **kwargs)`\n",
    "    * 計算`key`有幾種不同的值。\n",
    "    * `key`: index key的名稱，如果不是字串會產生`TypeError`。\n",
    "    * `filter`: 計算時會篩選條件。\n",
    "    * `maxTimeMS`: 這個命令允許執行的最長時間(milliseconds)。\n",
    "24. `create_index(keys, **kwargs)`\n",
    "    * 建立一個index，可以一個key或由多個key組成，例如`[('length', pymongo.ASCENDING), ('age', pymongo.DESCENDING)]`代表由兩個key組成的index，這個index只有當`filter`同時出現length與age時，才會發揮作用。\n",
    "    * `keys`: 字串代表一個key，或是一個list of tuple，代表多個key。\n",
    "    * `name`: 這個index的指定名稱，設為`None`表示自動產生。\n",
    "    * `unique`: 設為`True`表示key不會重複。\n",
    "    * `background`: 設為`True`表示在背景執行，避免影響前景的query。\n",
    "    * `sparse`: 設為`True`會忽略缺少指定key的documents。\n",
    "    * `bucketSize`: 在geoHaystack index中，多少個documents會聚成一群來計算經緯度。\n",
    "    * `min`: key的最小值。\n",
    "    * `max`: key的最大值。\n",
    "    * `expireAfterSeconds`: 如果key指定的欄位是UTC datetime，當現在時間與key值的時間相差超過`expireAfterSeconds`秒，就會自動刪除這份文件。\n",
    "    * `partialFilterExpression`: 指定partial index。\n",
    "25. `create_indexes(indexes)`\n",
    "    * 建立一或多個index。\n",
    "    * `indexes`: list of `IndexModel`。\n",
    "26. `drop_index(index_or_name)`\n",
    "    * 從collection刪除指定的index，如果index不存在或collection不存在，會產生`OperationFailure`。\n",
    "27. `drop_indexes()`: 刪除這個collection所有的index。如果collection不存在，會產生`OperationFailure`。\n",
    "28. `reindex()`: 重建這個collection上所有的index。\n",
    "29. `list_indexes()`: 列出這個collection上所有的index。\n",
    "30. `index_information()`: 傳回`dict`包含`{'index_name': information}`。\n",
    "31. `drop()`: 等同於`db.drop_collection('name')`。\n",
    "32. `rename(new_name, **kwargs)`: 修改collection的名稱。如果新的名稱已經存在，會產生`InvalidName`。\n",
    "33. `options()`: 傳回collection可用的選擇及目前的值。\n",
    "34. `group(key, condition, initial, reduce, finalize=None, **kwargs)`\n",
    "    * 類似SQL group by的操作。\n",
    "    * `key`: 設為`None`表示整個文件都拿來當key。設為list of keys會由這些key作group-by。設為字串會由單一的key作group-by。\n",
    "    * `condition`: 指定要考慮的row。\n",
    "    * `initial`: aggregation counter object的初始值。\n",
    "    * `reduce`: 表示aggregation function，格式為Javascript字串。\n",
    "    * `finalize`: 每一個輸出物件都會呼叫此function。\n",
    "35. `map_reduce(map, reduce, out, full_response=False, **kwargs)`\n",
    "    * 執行map/reduce操作，結果會存在新的collection。\n",
    "    * `map`: map function，格式為Javascript字串。\n",
    "    * `reduce`: reduce function，格式為Javascript字串。\n",
    "    * `out`: 輸出的collection名稱或是out物件(`dict`)。\n",
    "    * `full_response`: 設為`True`，會傳回命令完整的回應；預設為`False`，只傳回輸出的collection。\n",
    "36. `inline_map_reduce(map, reduce, full_response=False, **kwargs)`\n",
    "    * 執行inline map/reduce操作，表示在server的RAM中操作，結果不會產生result collection，而會傳回list of documents。\n",
    "    * `map`: map function，格式為Javascript字串。\n",
    "    * `reduce`: reduce function，格式為Javascript字串。\n",
    "    * `full_response`: 設為`True`，會傳回命令完整的回應；預設為`False`，只傳回list of documents。\n",
    "37. `parallel_scan(num_cursors)`\n",
    "    ```python\n",
    "    cursors = collection.parallel_scan(4)\n",
    "    threads = [threading.Thread(target=process_cursor, args=(cursor,)) for cursor in cursors]\n",
    "    for thread in threads: thread.start()\n",
    "    for thread in threads: thread.join()\n",
    "    ```\n",
    "    * 平行掃描整個collection，傳回可以平行處理的list of cursor。只要collection在過程中不要修改，每個document就會剛好出現一次。\n",
    "    * `num_cursors`: 要傳回幾個cursor。\n",
    "38. `initialize_unordered_bulk_op(bypass_document_validation=False)`\n",
    "    * 開始一個無序的batch write。這些write operation不會按照順序執行，但一定都會執行到。\n",
    "    * `bypass_document_validation`: 預設值`False`，設為`True`代表允許不合法的document被寫入。\n",
    "39. `initialize_ordered_bulk_op(bypass_document_validation=False)`\n",
    "    * 開始一個有序的batch write。這些write operation會按照順序執行，如果出錯，後面未執行的operation會被放棄。\n",
    "    * `bypass_document_validation`: 預設值`False`，設為`True`代表允許不合法的document被寫入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pymongo.cursor.Cursor`\n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "* 不應該直接創造這個class的物件，應該由`Collection.find()`來傳回`Cursor`。\n",
    "* cursor分為四類\n",
    "    * NON_TAILABLE: 標準cursor。\n",
    "    * TAILABLE: 用在capped collection上，當最後一筆資料讀取後不會關閉，而會停留在最後一筆document的位置。如果有新的document加入，可以再繼續讀新的資料。\n",
    "    * TAILABLE_AWAIT: 當最後一筆資料讀取後，server會等一段時間再關掉cursor，這樣在query過程中插入的document也可以被讀出來。\n",
    "    * EXHAUST: MongoDB會主動將資料送給client，而不會等client要求，這可以減少latency。\n",
    "\n",
    "\n",
    "### Methods and Members\n",
    "\n",
    "1. `c[index]` 或 `c.__getitem__(index)`\n",
    "    * 傳回`index`指定的documents，例如`c[50]`是傳回第50筆資料，`c[20:25]`相當於`skip=20`及`limit=5`。\n",
    "    * 如果`index`是負數或超過最大值，會產生`IndexError`。\n",
    "2. `add_option(mask)`: 設定query flag的bitmask，`mask`是2的幂次。\n",
    "3. `alive`: 在一般cursor中，這個值沒有用。在`TAILABLE` cursor中，這個值用來判斷cursor是否被server關閉。\n",
    "4. `batch_size(size)`: 一次batch傳回的document數量，這個值是唯讀的，應該在`Collection.find()`中設定。\n",
    "5. `clone()`: 傳回cursor的複製品，無論舊的cursor讀過多少資料，新的cursor內部的指標一定指向開頭。\n",
    "6. `close()`: 明確的關閉cursor。\n",
    "7. `count(with_limit_and_skip=False)`\n",
    "    * 取得query的documents總數。\n",
    "    * `with_limit_and_skip`: 設為`True`時，會考慮`limit`及`skip`的值，預設值為`False`。\n",
    "8. `cursor_id`: 一個long number代表id。\n",
    "9. `distinct(key)`: 統計指定的key有幾種不同的值。\n",
    "10. `explain()`: 傳回explain plan record。\n",
    "11. `hint(index)`: 新增一個hint，告訴Mongo要執行此query最適當的index。正確的設定可大幅增加query的效率，如果你查詢多個field，其中有一個有作index，就可以將此index作為hint。如果index不存在，不會產生錯誤。\n",
    "12. `max(spec)`: 設定index的上限值，`spec`是list of (field, limit)。\n",
    "13. `min(spec)`: 設定index的下限值，`spec`是list of (field, limit)。\n",
    "14. `next()`: 從cursor的buffer queue中讀取下一筆資料。\n",
    "15. `remove_option(mask)`: 消除query flag的bitmask，`mask`是2的幂次。\n",
    "16. `retrieved`: 目前已從server讀取的資料總數，相當於應用程式已讀取的資料數，加上buffer queue中剩餘的資料數。\n",
    "17. `rewind()`: 讓cursor回到開頭，會保持目前cursor的所有設定。\n",
    "18. `where(code)`: 在目前的query新增`$$where`述句，`code`是JavaScript expression，在每個document掃描時都會評估，只有傳回`True`的才會被讀取。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
